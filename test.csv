name,ring,quadrant,isNew,description
Dependency drift fitness function,Adopt,Techniques,FALSE,"<p>Fitness functions introduced by <a href=""/radar/techniques/evolutionary-architecture"">evolutionary architecture</a>, borrowed from <a href=""https://en.wikipedia.org/wiki/Evolutionary_computation#:%7E:text=In%20computer%20science%2C%20evolutionary%20computation,soft%20computing%20studying%20these%20algorithms."">evolutionary computing</a>, are executable functions that inform us if our applications and architecture are objectively moving away from their desired characteristics. They're essentially tests that can be incorporated into our release pipelines. One of the major characteristics of an application is the freshness of its dependencies to other libraries, APIs or environmental components that a <strong>dependency drift fitness function</strong> tracks to flag the out-of-date dependencies that require updating. With the growing and maturing number of tools that detect dependency drifts, such as <a href=""/radar/tools/dependabot"">Dependabot</a> or <a href=""/radar/tools/snyk"">Snyk</a>, we can easily incorporate dependency drift fitness functions into our software release process to take timely action in keeping our application dependencies up to date.</p>"
Run cost as architecture fitness function,Adopt,Techniques,FALSE,"<p>Automating the estimation, tracking and projection of cloud infrastructure's run cost is necessary for today's organizations. The cloud providers' savvy pricing models, combined with the proliferation of pricing parameters and the dynamic nature of today's architecture, can lead to surprisingly expensive run costs. For example, the price of <a href=""/radar/techniques/serverless-architecture"">serverless</a> based on API calls, event streaming solutions based on traffic or data processing clusters based on running jobs, all have a dynamic nature that changes over time as the architecture evolves. When our teams manage infrastructure on the cloud, implementing <strong>run cost as architecture fitness function</strong> is one of their early activities. This means that our teams can observe the cost of running services against the value delivered; when they see deviations from what was expected or acceptable, they'll discuss whether it's time to evolve the architecture. The observation and calculation of the run cost is implemented as an automated function.</p>"
Azure DevOps,Trial,Platforms,FALSE,"<p><strong><a href=""https://azure.microsoft.com/en-us/services/devops/"">Azure DevOps</a></strong> services contain a set of managed services, including hosted Git repos, CI/CD pipelines, automated testing tooling, backlog management tooling and artifact repository. We've seen our teams getting more experience in using this platform with good results, which means Azure DevOps is maturing. We particularly like its flexibility; it allows you to use the services you want even if they're from different providers. For instance, you could use an external Git repository while still using the Azure DevOps pipeline services. Our teams are especially excited about <a href=""https://azure.microsoft.com/en-us/services/devops/pipelines/"">Azure DevOps Pipelines</a>. Nevertheless, all the services offer a good developer experience that helps our teams deliver value.</p>"
Debezium,Trial,Platforms,FALSE,"<p><strong><a href=""https://debezium.io/"">Debezium</a></strong> is a <a href=""https://en.wikipedia.org/wiki/Change_data_capture"">change data capture (CDC)</a> platform that can stream database changes onto <a href=""/radar/tools/apache-kafka"">Kafka</a> topics. CDC is a popular technique with multiple use cases, including replicating data to other databases, feeding analytics systems, extracting microservices from monoliths and invalidating caches. Debezium reacts to changes in the database's log files and has CDC connectors for multiple databases, including Postgres, MySQL, Oracle and MongoDB. We're using Debezium in many projects, and it has worked very well for us.</p>"
Dependabot,Adopt,Tools,FALSE,"<p>Among the available tools for keeping dependencies up to date, <strong><a href=""http://dependabot.com/"">Dependabot</a></strong> is a solid default choice in our opinion. Dependabot's integration with <a href=""/radar/tools/github"">GitHub</a> is smooth and automatically sends you pull requests to update your dependencies to their latest versions. It can be enabled at the organization level, so it's very easy for teams to receive these pull requests. If you're not using GitHub, you can still use the Dependabot libraries within your build pipeline. If you're interested in an alternative tool, also consider <a href=""https://github.com/renovatebot/renovate"">Renovate</a>, which supports a wider range of services, including <a href=""/radar/tools/gitlab"">GitLab</a>, Bitbucket and <a href=""/radar/platforms/azure-devops"">Azure DevOps</a>.</p>"
Helm,Adopt,Tools,FALSE,"<p><strong><a href=""http://helm.sh/"">Helm</a></strong> is a package manager for <a href=""/radar/platforms/kubernetes"">Kubernetes</a>. It comes with a repository of curated Kubernetes applications that are maintained in the official <a href=""https://github.com/helm/charts"">Charts repository</a>. Since we last talked about Helm, Helm 3 has been released, and the most significant change is the removal of Tiller, the server-side component of Helm 2. The benefit of a design without Tiller is that you can only make changes to the Kubernetes cluster from the client side, that is, you can only modify the cluster according to the permissions you have as a user of the Helm command. We've used Helm in a number of client projects and its dependency management, templating and hook mechanism has greatly simplified the application lifecycle management in Kubernetes.</p>"
io-ts,Assess,languages-and-frameworks,TRUE,"<p>We've been really enjoying using <a href=""/radar/languages-and-frameworks/typescript"">TypeScript</a> for a while now and love the safety that the strong typing provides. However, getting data into the bounds of the type system, from say a call to a back-end service, can lead to run-time errors. One library that helps solve this problem is <strong><a href=""https://gcanti.github.io/io-ts/"">io-ts</a></strong>. It bridges the gap between compile-time type-checking and run-time consumption of external data by providing encode and decode functions. It can also be used as a custom type guard. According to our teams, it's an elegant solution to a rascal of a problem.</p>"
Kedro,Assess,languages-and-frameworks,TRUE,"<p>In the past we've talked about the <a href=""/radar/tools/experiment-tracking-tools-for-machine-learning"">improving</a> <a href=""/radar/tools/dvc"">tooling</a> for applying <a href=""/radar/techniques/continuous-delivery-for-machine-learning-cd4ml"">good engineering practices</a> in data science projects. <strong><a href=""https://github.com/quantumblacklabs/kedro"">Kedro</a></strong> is another good addition in this space. It's a development workflow framework for data science projects that brings a standardized approach to building production-ready data and machine-learning pipelines. We like the focus on software engineering practices and good design with its emphasis on test-driven development, modularity, versioning and good hygiene practices such as keeping credentials out of the codebase.</p>"
